# -*- coding: utf-8 -*-
"""Stroke prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rO2HZfCSVxPag1q5uFkEqIaN4Q7L-ujk
"""



"""Importing"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import RobustScaler
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.metrics import classification_report

"""Dataset import"""

df = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')

"""Data analysis"""

df.shape

df.head(3)

df.info()

##Selecting numerical features
numerical_data = df.select_dtypes(include='number')

#append the features of numerical_data to list
numerical_features=numerical_data.columns.tolist()

print(f'There are {len(numerical_features)} numerical features:', '\n')
print(numerical_features)
print()

#Selecting categoricalfeatures
categorical_data=df.select_dtypes(include= 'object')

#append the features of categorical_data to list
categorical_features=categorical_data.columns.tolist()

print(f'There are {len(categorical_features)} categorical features:', '\n')
print(categorical_features)

numerical_data.describe().T

categorical_data.describe().T

numerical_data.hist(figsize=(12,12),bins=20)
plt.show()

# Select only numerical columns for boxplot analysis
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Set up the figure
plt.figure(figsize=(20, 30))

# Plot boxplots for each numerical feature including the target variable 'OUTCOME'
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(len(numeric_cols), 1, i)
    sns.boxplot(x=df[col], color='skyblue')
    plt.title(f'Boxplot of {col}', fontsize=12)
    plt.tight_layout()

plt.show()

numerical_data.isnull().sum()

for col in categorical_features:
    plt.title(f'Distribution of {col}')
    categorical_data[col].value_counts().sort_index().plot(kind='bar', rot=0, xlabel=col,ylabel='count')
    plt.show()

correlation_matrix = numerical_data.corr()
correlation_matrix

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.3f', linewidths=0.3)
plt.show()

class_counts=df.groupby("stroke").size()
columns=['stroke','count','percentage']
stroke=[0,1]
count=list()
percentage=list()

#Calculate the percentage of each value of the stroke variable from total
for val in range(2):
    count.append(class_counts[val])
    percent=(class_counts[val]/df.shape[0])*100
    percentage.append(percent)

# Convert the calulated values into a dataframe
imbalance_df=pd.DataFrame(list(zip(stroke,count,percentage)),columns=columns)
imbalance_df

sns.barplot(data=imbalance_df,x=imbalance_df['stroke'],y=imbalance_df['percentage'])
plt.show()

"""Data Preprocessing"""

df['bmi'] = df['bmi'].fillna(df['bmi'].median())

df = df.drop(['id'], axis = 1)
print(df.shape)
df.head(2)

df = df[df['work_type'] != 'Never_worked']
s=df['work_type'].nunique()
print(s)

plt.title(f'Distribution of {col}')
df['work_type'].value_counts().sort_index().plot(kind='bar', rot=0, xlabel=col,ylabel='count')
plt.show()
df.shape

Label_Encoder = LabelEncoder()
df["gender"] = Label_Encoder.fit_transform(df["gender"])
df["ever_married"] = Label_Encoder.fit_transform(df["ever_married"])
df["Residence_type"] = Label_Encoder.fit_transform(df["Residence_type"])
df["smoking_status"] = Label_Encoder.fit_transform(df["smoking_status"])
df["work_type"] = Label_Encoder.fit_transform(df["work_type"])

df.head(3)

Q1 = df['avg_glucose_level'].quantile(0.25)
Q3 = df['avg_glucose_level'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df_cleaned = df[(df['avg_glucose_level'] >= lower_bound) & (df['avg_glucose_level'] <= upper_bound)]
df_cleaned.shape

plt.figure(figsize=(6, 5))
plt.boxplot(df_cleaned['avg_glucose_level'], vert=True, patch_artist=True, boxprops=dict(facecolor='skyblue'))
plt.title('Box Plot of Average Glucose Level')
plt.ylabel('Avg Glucose Level')
plt.grid(True)
plt.show()

numer_data = df_cleaned.select_dtypes(include='number')
numer_data.describe().T

Q1 = df_cleaned['bmi'].quantile(0.25)
Q3 = df_cleaned['bmi'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df_cleaned = df_cleaned[(df_cleaned['bmi'] >= lower_bound) & (df_cleaned['bmi'] <= upper_bound)]

df_cleaned.shape

plt.figure(figsize=(6, 5))
plt.boxplot(df_cleaned['bmi'], vert=True, patch_artist=True, boxprops=dict(facecolor='skyblue'))
plt.title('Box Plot of Average Glucose Level')
plt.ylabel('Avg Glucose Level')
plt.grid(True)
plt.show()

"""Train - Test split"""

x = df_cleaned.drop("stroke", axis=1)
y = df_cleaned["stroke"]
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

y_train.shape

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

smote = SMOTE(random_state=42)
X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)

X_train_scaled.shape

y_train.shape

"""Define Model"""

models = {"Logistic Regression": LogisticRegression(), "KNN": KNeighborsClassifier(),"Random Forest": RandomForestClassifier(),'Neural Network': MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=100, random_state=42)}

plt.figure(figsize=(10, 8))

for name, model in models.items():
    # Fit
    model.fit(X_train_scaled, y_train)

    y_probs = model.predict_proba(X_test_scaled)[:, 1]

    # ROC and AUC
    fpr, tpr, _ = roc_curve(y_test, y_probs)
    roc_auc = auc(fpr, tpr)

    # Plot
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

# Plot random line
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')

# Final plot setup
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison - Stroke Dataset")
plt.legend(loc="lower right")
plt.grid()
plt.show()

y_pred_models = []
for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    y_pred_models.append(y_pred)
    cm = confusion_matrix(y_test, y_pred)
    ConfusionMatrixDisplay(cm, display_labels=["No Stroke", "Stroke"]).plot(cmap="Blues")
    plt.title(name)
    plt.show()

x = 0
for name, model in models.items():
    print(f'{name}:')
    print(classification_report(y_test, y_pred_models[x], target_names=["No Stroke", "Stroke"]))
    x+=1

models = ['Logistic Regression', 'Random Forest', 'KNN','Neural Network']
accuracy = [accuracy_score(y_test, y_pred_models[0]), accuracy_score(y_test, y_pred_models[1]), accuracy_score(y_test, y_pred_models[2]),accuracy_score(y_test, y_pred_models[3])]

# Bar plot
plt.figure(figsize=(8, 5))
bars = plt.bar(models, accuracy, color=['skyblue', 'lightgreen', 'salmon','yellow'])

# Add value labels on top of bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval:.2f}', ha='center', fontsize=12)

# Titles and labels
plt.ylim(0, 1.1)
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.xlabel('Models')
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

# Train the model
mlp = MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42)
mlp.fit(X_train_scaled, y_train)

# Plot the loss curve
plt.plot(mlp.loss_curve_)
plt.title("MLPClassifier Loss Curve")
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.grid(True)
plt.show()